{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc33ee5-8835-4e1b-88ad-bd48c02d4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from statsmodels.stats.contingency_tables import cochrans_q\n",
    "from scipy.stats import combine_pvalues\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84038279-61a3-4f3f-910a-d5def06157d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function `read_json_answers` is designed to extract and aggregate \n",
    "# structured responses generated by a Large Language Model (LLM) from a JSON file. \n",
    "# Specifically, it reads the file located at `file_path`, parses its contents, \n",
    "# and retrieves all values associated with the key `answer` from objects within a list structure.\n",
    "\n",
    "def read_json_answers(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    answers = []\n",
    "    if isinstance(data, list):\n",
    "        for obj in data:\n",
    "            if isinstance(obj, dict) and \"answer\" in obj:\n",
    "                answers.append(obj[\"answer\"])\n",
    "    return answers\n",
    "\n",
    "# The function `read_unstructured_parsed` serves a similar purpose to \n",
    "# `read_json_answers` but operates on unstructured outputs that have been \n",
    "# post-processed into a structured format. It reads a JSON file \n",
    "# containing a list of dictionaries and extracts values associated with the key `parsed`.\n",
    "\n",
    "def read_unstructured_parsed(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    answers = []\n",
    "    if isinstance(data, list):\n",
    "        for obj in data:\n",
    "            if isinstance(obj, dict) and \"parsed\" in obj:\n",
    "                answers.append(obj[\"parsed\"])\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f8e498-2a1b-4215-b5fa-c4a9c454dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list recording answers from structured output of LLM\n",
    "# These are read from files located in the `sot_results` directory, with each \n",
    "# file corresponding to a specific persona or role (standard, artist, chef, \n",
    "# detective, judge). The extracted lists enable comparative evaluation of instruction intervention \n",
    "# conditioning influences LLM behavior in structured contexts.\n",
    "json_standard_answers = read_json_answers(\"sot_results/seven_objects_json.json\")\n",
    "json_artist_answers = read_json_answers(\"sot_results/seven_objects_json_artist.json\")\n",
    "json_chef_answers = read_json_answers(\"sot_results/seven_objects_json_chef.json\")\n",
    "json_detective_answers = read_json_answers(\"sot_results/seven_objects_json_detective.json\")\n",
    "json_judge_answers = read_json_answers(\"sot_results/seven_objects_json_judge.json\")\n",
    "\n",
    "# Extract the list recording answers from unstructured output of LLM\n",
    "unstructured_standard_answers = read_unstructured_parsed(\"sot_results/seven_objects_unstructured_parsed.json\")\n",
    "unstructured_artist_answers = read_unstructured_parsed(\"sot_results/seven_objects_unstructured_artist_parsed.json\")\n",
    "unstructured_chef_answers = read_unstructured_parsed(\"sot_results/seven_objects_unstructured_chef_parsed.json\")\n",
    "unstructured_detective_answers = read_unstructured_parsed(\"sot_results/seven_objects_unstructured_detective_parsed.json\")\n",
    "unstructured_judge_answers = read_unstructured_parsed(\"sot_results/seven_objects_unstructured_judge_parsed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333d99d2-a5eb-4906-b11b-9bbcb29d956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block computes binary correctness indicators for each LLM-generated response \n",
    "# by comparing it against the ground truth labels provided in the dataset. The evaluation \n",
    "# metric is based on exact match between the predicted answer and the reference label.\n",
    "# The ground truth labels are loaded from `data/seven_objects.json`. \n",
    "# Each comparison yields a binary outcome: `1` if the predicted answer contains the \n",
    "# ground truth label (indicating correctness), and `0` otherwise. These results are \n",
    "# stored in separate lists for each persona (standard, artist, chef, detective, judge) \n",
    "# and for each output type (structured vs. unstructured).\n",
    "\n",
    "with open(\"data/seven_objects.json\", \"r\") as f:\n",
    "    label = json.load(f)\n",
    "unstructured_standard_results = []\n",
    "unstructured_artist_results = []\n",
    "unstructured_chef_results = []\n",
    "unstructured_detective_results = []\n",
    "unstructured_judge_results = []\n",
    "\n",
    "json_standard_results = []\n",
    "json_artist_results = []\n",
    "json_chef_results = []\n",
    "json_detective_results = []\n",
    "json_judge_results = []\n",
    "\n",
    "for i in range(len(unstructured_standard_answers)):\n",
    "    label_tmp = next((k for k, v in label[\"examples\"][i]['target_scores'].items() if v == 1), None)\n",
    "    label_tmp = label_tmp.replace(\" ball.\", \"\")\n",
    "    # Unstructured answers\n",
    "    if label_tmp.lower() in unstructured_standard_answers[i].lower():\n",
    "        unstructured_standard_results.append(1)\n",
    "    else:\n",
    "        unstructured_standard_results.append(0)\n",
    "        \n",
    "    if label_tmp.lower() in unstructured_artist_answers[i].lower():\n",
    "        unstructured_artist_results.append(1)\n",
    "    else:\n",
    "        unstructured_artist_results.append(0)\n",
    "        \n",
    "    if label_tmp.lower() in unstructured_chef_answers[i].lower():\n",
    "        unstructured_chef_results.append(1)\n",
    "    else:\n",
    "        unstructured_chef_results.append(0)\n",
    "        \n",
    "    if label_tmp.lower() in unstructured_detective_answers[i].lower():\n",
    "        unstructured_detective_results.append(1)\n",
    "    else:\n",
    "        unstructured_detective_results.append(0)\n",
    "        \n",
    "    if label_tmp.lower() in unstructured_judge_answers[i].lower():\n",
    "        unstructured_judge_results.append(1)\n",
    "    else:\n",
    "        unstructured_judge_results.append(0)\n",
    "    \n",
    "    # Structured answers\n",
    "    if label_tmp.lower() in json_standard_answers[i].lower():\n",
    "        json_standard_results.append(1)\n",
    "    else:\n",
    "        json_standard_results.append(0)   \n",
    "        \n",
    "    if label_tmp.lower() in json_artist_answers[i].lower():\n",
    "        json_artist_results.append(1)\n",
    "    else:\n",
    "        json_artist_results.append(0) \n",
    "        \n",
    "    if label_tmp.lower() in json_chef_answers[i].lower():\n",
    "        json_chef_results.append(1)\n",
    "    else:\n",
    "        json_chef_results.append(0) \n",
    "        \n",
    "    if label_tmp.lower() in json_detective_answers[i].lower():\n",
    "        json_detective_results.append(1)\n",
    "    else:\n",
    "        json_detective_results.append(0) \n",
    "        \n",
    "    if label_tmp.lower() in json_judge_answers[i].lower():\n",
    "        json_judge_results.append(1)\n",
    "    else:\n",
    "        json_judge_results.append(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1547d1bb-af7d-4952-8b75-a03e3a2871f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy of unstructured format with diverse instruction: 0.992\n",
      "Averaged accuracy of JSON format with diverse instruction: 0.965\n",
      "Combined p-value across strata (Stouffer’s method): 0.030\n"
     ]
    }
   ],
   "source": [
    "# This section evaluates whether the output format (structured JSON vs. unstructured text) \n",
    "# significantly influences the accuracy of LLM-generated responses under diverse instructional conditions.\n",
    "# Compute and display the averaged accuracy for each output \n",
    "# format across all persona-based instructions (standard, artist, chef, detective, judge). \n",
    "print(f\"Averaged accuracy of unstructured format with diverse instruction: {format((sum(unstructured_standard_results)+sum(unstructured_artist_results)+sum(unstructured_chef_results)+sum(unstructured_detective_results)+sum(unstructured_judge_results))/(5*len(unstructured_standard_results)),'.3f')}\")\n",
    "print(f\"Averaged accuracy of JSON format with diverse instruction: {format((sum(json_standard_results)+sum(json_artist_results)+sum(json_chef_results)+sum(json_detective_results)+sum(json_judge_results))/(5*len(json_standard_results)),'.3f')}\")\n",
    "\n",
    "# To formally test whether the observed differences are statistically significant, \n",
    "# McNemar's test is applied within each stratum (persona). McNemar's test is appropriate \n",
    "# for paired nominal data and evaluates whether the marginal proportions differ between \n",
    "# two correlated binary outcomes (here, correctness under JSON vs. unstructured format).\n",
    "data_subsets = [\n",
    "    # Stratum of control on standard instruction\n",
    "    (np.array(json_standard_results), np.array(unstructured_standard_results)),\n",
    "    # Stratum of control on artist instruction\n",
    "    (np.array(json_artist_results), np.array(unstructured_artist_results)),\n",
    "    # Stratum of control on chef instruction\n",
    "    (np.array(json_chef_results), np.array(unstructured_chef_results)),\n",
    "    # Stratum of control on detective instruction\n",
    "    (np.array(json_detective_results), np.array(unstructured_detective_results)),\n",
    "    # Stratum of control on judge instruction\n",
    "    (np.array(json_judge_results), np.array(unstructured_judge_results)),\n",
    "]\n",
    "\n",
    "p_values = []\n",
    "\n",
    "for i, (correct_D, correct_E) in enumerate(data_subsets, 1):\n",
    "    # Build contingency table for this stratum\n",
    "    table = np.zeros((2, 2), dtype=int)\n",
    "    for d, e in zip(correct_D, correct_E):\n",
    "        table[d, e] += 1\n",
    "\n",
    "    # Run McNemar's test\n",
    "    result = mcnemar(table, exact=True)\n",
    "    p_values.append(result.pvalue)\n",
    "\n",
    "# To aggregate evidence across multiple strata (personas), Stouffer’s method is employed. \n",
    "# This technique combines p-values by converting them into Z-scores and computing a weighted \n",
    "# sum, adjusted for correlation among strata (due to shared samples). The correlation-adjusted \n",
    "# Stouffer Z statistic accounts for potential dependence between tests, yielding a combined \n",
    "# p-value that reflects the overall significance of output format effects.\n",
    "# Convert p-values to Z-scores (two-sided)\n",
    "z_scores = norm.isf(np.array(p_values) / 2)  # inverse survival function\n",
    "\n",
    "# Assume weights (e.g., uniform or by number of samples per stratum)\n",
    "weights = np.ones_like(z_scores)\n",
    "# Assume correlation between strata (due to shared samples)\n",
    "rho = 0.3\n",
    "k = len(p_values)\n",
    "R = np.full((k, k), rho)\n",
    "np.fill_diagonal(R, 1)  # correlation matrix\n",
    "\n",
    "# Stouffer's Z with correlation adjustment\n",
    "numerator = np.sum(weights * z_scores)\n",
    "denominator = np.sqrt(np.dot(weights, R @ weights))\n",
    "z_combined = numerator / denominator\n",
    "p_combined = 2 * norm.sf(abs(z_combined))\n",
    "\n",
    "# Report combined significance level\n",
    "print(f\"Combined p-value across strata (Stouffer’s method): {p_combined:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9f1ffa-bcab-4986-9566-0878ba1986bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy of unstructured & JSON format with standard instruction: 0.990\n",
      "Averaged accuracy of unstructured & JSON format with intervened instruction: 0.976\n",
      "Combined p-value across strata (Stouffer’s method): 0.019\n"
     ]
    }
   ],
   "source": [
    "# This section investigates whether variations in instructional framing (standard vs. \n",
    "# persona-based interventions) significantly influence the accuracy of LLM-generated \n",
    "# responses across both output formats (structured JSON and unstructured text).\n",
    "print(f\"Averaged accuracy of unstructured & JSON format with standard instruction: {format((sum(unstructured_standard_results)+sum(json_standard_results))/(2*len(unstructured_standard_results)),'.3f')}\")\n",
    "print(f\"Averaged accuracy of unstructured & JSON format with intervened instruction: {format((sum(unstructured_artist_results)+sum(unstructured_chef_results)+sum(unstructured_detective_results)+sum(unstructured_judge_results)+sum(json_artist_results)+sum(json_chef_results)+sum(json_detective_results)+sum(json_judge_results))/(8*len(json_standard_results)),'.3f')}\")\n",
    "\n",
    "stratum_json = np.array([json_standard_results, json_artist_results, json_chef_results, json_detective_results, json_judge_results]).transpose()\n",
    "stratum_unstructured = np.array([unstructured_standard_results, unstructured_artist_results, unstructured_chef_results, unstructured_detective_results, unstructured_judge_results]).transpose()\n",
    "data_strata = [stratum_json, stratum_unstructured]\n",
    "\n",
    "# Run Cochran's Q test to assess whether the differences in accuracy across \n",
    "# multiple instructional conditions are statistically significant within each output format\n",
    "# Two strata are considered:\n",
    "# Stratum 1: Structured JSON outputs across all instructions.\n",
    "# Stratum 2: Unstructured outputs across all instructions.\n",
    "# Apply Cochran's Q test to each stratum and collect p-values\n",
    "\n",
    "p_values = []\n",
    "\n",
    "for i, data in enumerate(data_strata):\n",
    "    result = cochrans_q(data)\n",
    "    p_values.append(result.pvalue)\n",
    "    \n",
    "# To aggregate evidence across multiple strata (personas), Stouffer’s method is employed. \n",
    "# This technique combines p-values by converting them into Z-scores and computing a weighted \n",
    "# sum, adjusted for correlation among strata (due to shared samples). The correlation-adjusted \n",
    "# Stouffer Z statistic accounts for potential dependence between tests, yielding a combined \n",
    "# p-value that reflects the overall significance of output format effects.\n",
    "# Convert p-values to Z-scores (two-sided)\n",
    "z_scores = norm.isf(np.array(p_values) / 2)  # inverse survival function\n",
    "\n",
    "# Assume weights (e.g., uniform or by number of samples per stratum)\n",
    "weights = np.ones_like(z_scores)\n",
    "# Assume correlation between strata (due to shared samples)\n",
    "rho = 0.3\n",
    "k = len(p_values)\n",
    "R = np.full((k, k), rho)\n",
    "np.fill_diagonal(R, 1)  # correlation matrix\n",
    "\n",
    "# Stouffer's Z with correlation adjustment\n",
    "numerator = np.sum(weights * z_scores)\n",
    "denominator = np.sqrt(np.dot(weights, R @ weights))\n",
    "z_combined = numerator / denominator\n",
    "p_combined = 2 * norm.sf(abs(z_combined))\n",
    "\n",
    "# Report combined significance level\n",
    "print(f\"Combined p-value across strata (Stouffer’s method): {p_combined:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d17b32-56d1-4e27-87f3-e65ec209df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section constructs a dataset for modeling the conditional association between \n",
    "# output format (structured vs. unstructured) and instruction type (standard vs. persona-based) on LLM generation quality. \n",
    "# The analysis is framed within a mixed-effects multinomial logistic regression.\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\n",
    "# Constructs a pandas DataFrame with three key variables:\n",
    "# `Z` (Instruction Type): Encoded as categorical labels ('a' = standard, 'b' = artist, \n",
    "# 'c' = chef, 'd' = detective, 'e' = judge). This variable captures the instructional framing applied to the LLM.\n",
    "# `X` (Output Format): Binary indicator where `1` denotes structured JSON output and `0` denotes unstructured text output.\n",
    "# `Y` (Generation Quality): Binary outcome where `1` indicates correctness (answer matches ground truth) and `0` indicates incorrectness.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Z': np.concatenate([np.repeat('a', len(json_standard_results)),\n",
    "                         np.repeat('b', len(json_artist_results)),\n",
    "                         np.repeat('c', len(json_chef_results)),\n",
    "                         np.repeat('d', len(json_detective_results)),\n",
    "                         np.repeat('e', len(json_judge_results)),\n",
    "                         # Unstructured\n",
    "                         np.repeat('a', len(unstructured_standard_results)),\n",
    "                         np.repeat('b', len(unstructured_artist_results)),\n",
    "                         np.repeat('c', len(unstructured_chef_results)),\n",
    "                         np.repeat('d', len(unstructured_detective_results)),\n",
    "                         np.repeat('e', len(unstructured_judge_results)),\n",
    "                        ]),\n",
    "    'X': np.concatenate([np.repeat(1, len(json_standard_results)),\n",
    "                         np.repeat(1, len(json_artist_results)),\n",
    "                         np.repeat(1, len(json_chef_results)),\n",
    "                         np.repeat(1, len(json_detective_results)),\n",
    "                         np.repeat(1, len(json_judge_results)),\n",
    "                         # Unstructured\n",
    "                         np.repeat(0, len(unstructured_standard_results)),\n",
    "                         np.repeat(0, len(unstructured_artist_results)),\n",
    "                         np.repeat(0, len(unstructured_chef_results)),\n",
    "                         np.repeat(0, len(unstructured_detective_results)),\n",
    "                         np.repeat(0, len(unstructured_judge_results)),\n",
    "                        ]),\n",
    "    'Y': np.concatenate([np.repeat(0, len(np.where(np.array(json_standard_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(json_standard_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(json_artist_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(json_artist_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(json_chef_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(json_chef_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(json_detective_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(json_detective_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(json_judge_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(json_judge_results)==1)[0])),\n",
    "                         # Unstructured\n",
    "                         np.repeat(0, len(np.where(np.array(unstructured_standard_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(unstructured_standard_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(unstructured_artist_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(unstructured_artist_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(unstructured_chef_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(unstructured_chef_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(unstructured_detective_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(unstructured_detective_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(unstructured_judge_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(unstructured_judge_results)==1)[0])),\n",
    "                        ])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7f53f38-a17e-4799-88ba-f4b0ac59888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Binomial Mixed GLM Results\n",
      "====================================================\n",
      "      Type Post. Mean Post. SD   SD  SD (LB) SD (UB)\n",
      "----------------------------------------------------\n",
      "const    M     0.6237   0.0447                      \n",
      "Z_b      M    -0.0159   0.1000                      \n",
      "Z_c      M    -0.0396   0.1003                      \n",
      "Z_d      M     0.0017   0.0997                      \n",
      "Z_e      M    -0.0071   0.0999                      \n",
      "VC_1     V     0.0000   1.0000 1.000   0.135   7.389\n",
      "VC_2     V    -0.0967   0.4561 0.908   0.365   2.260\n",
      "====================================================\n",
      "Parameter types are mean structure (M) and variance\n",
      "structure (V)\n",
      "Variance parameters are modeled as log standard\n",
      "deviations\n"
     ]
    }
   ],
   "source": [
    "# Prepare design matrices for mixed-effects multinomial logistic regression\n",
    "df_dummy = pd.get_dummies(df, columns=['Z'], drop_first=True)\n",
    "# Define model components\n",
    "endog = df_dummy['X']\n",
    "exog = sm.add_constant(df_dummy[[col for col in df_dummy.columns if col.startswith('Z_')]])  # fixed effects\n",
    "groups = df_dummy['Y']\n",
    "exog_re = pd.get_dummies(groups)  # random intercepts per stratum\n",
    "ident = np.ones(exog_re.shape[1], dtype=int)\n",
    "# Fit mixed-effects multinomial logistic regression\n",
    "model = BinomialBayesMixedGLM(endog, exog, exog_re, ident=ident)\n",
    "result = model.fit_vb()\n",
    "# Display posterior summaries for fixed and random effects\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f8e0bc4-81f2-4b11-9c79-7b359c23b1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const                coef =  0.6237, SE = 0.0447, z = 13.95, p = 0.0000\n",
      "Z_b                  coef = -0.0159, SE = 0.1000, z = -0.16, p = 0.8740\n",
      "Z_c                  coef = -0.0396, SE = 0.1003, z = -0.39, p = 0.6933\n",
      "Z_d                  coef =  0.0017, SE = 0.0997, z = 0.02, p = 0.9863\n",
      "Z_e                  coef = -0.0071, SE = 0.0999, z = -0.07, p = 0.9437\n"
     ]
    }
   ],
   "source": [
    "# Extract coefficient names, values, and std errors\n",
    "# names of fixed effects (same order as fe_mean)\n",
    "param_names = model.exog_names  \n",
    "# posterior means of fixed effects\n",
    "coefs = result.fe_mean          \n",
    "# posterior standard deviations\n",
    "ses = result.fe_sd              \n",
    "\n",
    "# Compute z-scores and p-values\n",
    "z_scores = coefs / ses\n",
    "# two-tailed p-values\n",
    "p_values = 2 * (1 - norm.cdf(np.abs(z_scores)))  \n",
    "\n",
    "# Display formatted summary for each fixed effect\n",
    "# We use the most significant p value as the representative value to suprious correlation\n",
    "for name, coef, se, z, p in zip(param_names, coefs, ses, z_scores, p_values):\n",
    "    print(f\"{name:20} coef = {coef: .4f}, SE = {se:.4f}, z = {z:.2f}, p = {p:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
