{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc33ee5-8835-4e1b-88ad-bd48c02d4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "import re\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from statsmodels.stats.contingency_tables import cochrans_q\n",
    "from scipy.stats import combine_pvalues\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84038279-61a3-4f3f-910a-d5def06157d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml_answers(file_path, positions):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    data = [data[i] for i in positions]\n",
    "    answers = []\n",
    "    for obj in data:\n",
    "        obj = obj.replace(\"```\", \"\")\n",
    "        obj = \"reasoning:\" + obj.split(\"reasoning:\")[-1]\n",
    "        obj = yaml.safe_load(obj)\n",
    "        number = str(obj[\"answer\"]).replace(',', '')\n",
    "        number = re.findall(r'\\d+\\.\\d+|\\d+', number)\n",
    "        if len(number) != 0:\n",
    "            answers.append(number[-1])\n",
    "        else:\n",
    "            answers.append('10086')\n",
    "    return answers\n",
    "\n",
    "def read_unstructured_parsed(file_path, positions):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    data = [data[i] for i in positions]\n",
    "    answers = []\n",
    "    if isinstance(data, list):\n",
    "        for obj in data:\n",
    "            if isinstance(obj, dict) and \"parsed\" in obj:\n",
    "                number = str(obj[\"parsed\"]).replace(',', '')\n",
    "                number = re.findall(r'\\d+\\.\\d+|\\d+', number)\n",
    "                if len(number) != 0:\n",
    "                    answers.append(number[0])\n",
    "                else:\n",
    "                    answers.append('10086')\n",
    "    return answers\n",
    "\n",
    "def validate_yaml_structure(yaml_object):\n",
    "    try:\n",
    "        # Parse YAML string\n",
    "        data = yaml.safe_load(yaml_object)\n",
    "        \n",
    "        # Check that it's a dictionary\n",
    "        if not isinstance(data, dict):\n",
    "            return False\n",
    "\n",
    "        # Check required keys\n",
    "        if \"reasoning\" not in data:\n",
    "            return False\n",
    "        if \"answer\" not in data:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    except yaml.YAMLError as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ea8b5a-b926-408d-96fd-0f5c39541e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_id(path):\n",
    "    with open(path) as json_data:\n",
    "        data_pred = json.load(json_data)\n",
    "    response_id = []\n",
    "    for i in range(200):\n",
    "        output = data_pred[i]\n",
    "        output = output.replace(\"```\", \"\")\n",
    "        output = \"reasoning:\" + output.split(\"reasoning:\")[-1]\n",
    "        if validate_yaml_structure(output):\n",
    "            response_id.append(1)\n",
    "        else:\n",
    "            response_id.append(0)\n",
    "    return response_id\n",
    "\n",
    "def common_one_positions(*lists):\n",
    "    if not lists:\n",
    "        return []\n",
    "    \n",
    "    # Use zip to group elements by position, then check if all are 1\n",
    "    return [i for i, values in enumerate(zip(*lists)) if all(v == 1 for v in values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95ea75d-7f6a-4808-a76b-ae4aad1b3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_id_standard = get_response_id('results/llama_8b_yaml.json')\n",
    "response_id_artist = get_response_id('results/llama_8b_yaml_artist.json')\n",
    "response_id_chef = get_response_id('results/llama_8b_yaml_chef.json')\n",
    "response_id_detective = get_response_id('results/llama_8b_yaml_detective.json')\n",
    "response_id_judge = get_response_id('results/llama_8b_yaml_judge.json')\n",
    "positions = common_one_positions(response_id_standard, response_id_artist, response_id_chef, response_id_detective, response_id_judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f8e498-2a1b-4215-b5fa-c4a9c454dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured answers\n",
    "yaml_standard_answers = read_yaml_answers(\"results/llama_8b_yaml.json\", positions)\n",
    "yaml_artist_answers = read_yaml_answers(\"results/llama_8b_yaml_artist.json\", positions)\n",
    "yaml_chef_answers = read_yaml_answers(\"results/llama_8b_yaml_chef.json\", positions)\n",
    "yaml_detective_answers = read_yaml_answers(\"results/llama_8b_yaml_detective.json\", positions)\n",
    "yaml_judge_answers = read_yaml_answers(\"results/llama_8b_yaml_judge.json\", positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e7a2578-3e0d-4de1-acb5-6329b7110f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstructured answers\n",
    "unstructured_standard_answers = read_unstructured_parsed(\"results/llama_8b_unstructured_parsed.json\", positions)\n",
    "unstructured_artist_answers = read_unstructured_parsed(\"results/llama_8b_unstructured_artist_parsed.json\", positions)\n",
    "unstructured_chef_answers = read_unstructured_parsed(\"results/llama_8b_unstructured_chef_parsed.json\", positions)\n",
    "unstructured_detective_answers = read_unstructured_parsed(\"results/llama_8b_unstructured_detective_parsed.json\", positions)\n",
    "unstructured_judge_answers = read_unstructured_parsed(\"results/llama_8b_unstructured_judge_parsed.json\", positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333d99d2-a5eb-4906-b11b-9bbcb29d956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/gsm8k_test.json\", \"r\") as f:\n",
    "    label = json.load(f)\n",
    "label = [label[i] for i in positions]\n",
    "\n",
    "unstructured_standard_results = []\n",
    "unstructured_artist_results = []\n",
    "unstructured_chef_results = []\n",
    "unstructured_detective_results = []\n",
    "unstructured_judge_results = []\n",
    "\n",
    "yaml_standard_results = []\n",
    "yaml_artist_results = []\n",
    "yaml_chef_results = []\n",
    "yaml_detective_results = []\n",
    "yaml_judge_results = []\n",
    "\n",
    "for i in range(len(unstructured_standard_answers)):\n",
    "    label_tmp = float(label[i]['answer'].split(\"\\n#### \")[-1].replace(',', ''))\n",
    "    # Unstructured answers\n",
    "    if label_tmp == float(unstructured_standard_answers[i]):\n",
    "        unstructured_standard_results.append(1)\n",
    "    else:\n",
    "        unstructured_standard_results.append(0)\n",
    "        \n",
    "    if label_tmp == float(unstructured_artist_answers[i]):\n",
    "        unstructured_artist_results.append(1)\n",
    "    else:\n",
    "        unstructured_artist_results.append(0)\n",
    "        \n",
    "    if label_tmp == float(unstructured_chef_answers[i]):\n",
    "        unstructured_chef_results.append(1)\n",
    "    else:\n",
    "        unstructured_chef_results.append(0)\n",
    "        \n",
    "    if label_tmp == float(unstructured_detective_answers[i]):\n",
    "        unstructured_detective_results.append(1)\n",
    "    else:\n",
    "        unstructured_detective_results.append(0)\n",
    "        \n",
    "    if label_tmp == float(unstructured_judge_answers[i]):\n",
    "        unstructured_judge_results.append(1)\n",
    "    else:\n",
    "        unstructured_judge_results.append(0)\n",
    "    \n",
    "    # Structured answers\n",
    "    if label_tmp == float(yaml_standard_answers[i]):\n",
    "        yaml_standard_results.append(1)\n",
    "    else:\n",
    "        yaml_standard_results.append(0)   \n",
    "        \n",
    "    if label_tmp == float(yaml_artist_answers[i]):\n",
    "        yaml_artist_results.append(1)\n",
    "    else:\n",
    "        yaml_artist_results.append(0) \n",
    "        \n",
    "    if label_tmp == float(yaml_chef_answers[i]):\n",
    "        yaml_chef_results.append(1)\n",
    "    else:\n",
    "        yaml_chef_results.append(0) \n",
    "        \n",
    "    if label_tmp == float(yaml_detective_answers[i]):\n",
    "        yaml_detective_results.append(1)\n",
    "    else:\n",
    "        yaml_detective_results.append(0) \n",
    "        \n",
    "    if label_tmp == float(yaml_judge_answers[i]):\n",
    "        yaml_judge_results.append(1)\n",
    "    else:\n",
    "        yaml_judge_results.append(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1547d1bb-af7d-4952-8b75-a03e3a2871f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy of unstructured format with diverse instruction: 0.845\n",
      "Averaged accuracy of YAML format with diverse instruction: 0.799\n",
      "Combined p-value across strata (Stoufferâ€™s method): 0.003\n"
     ]
    }
   ],
   "source": [
    "# Test whether output format significantly influences LLMs' generation\n",
    "print(f\"Averaged accuracy of unstructured format with diverse instruction: {format((sum(unstructured_standard_results)+sum(unstructured_artist_results)+sum(unstructured_chef_results)+sum(unstructured_detective_results)+sum(unstructured_judge_results))/(5*len(unstructured_standard_results)),'.3f')}\")\n",
    "print(f\"Averaged accuracy of YAML format with diverse instruction: {format((sum(yaml_standard_results)+sum(yaml_artist_results)+sum(yaml_chef_results)+sum(yaml_detective_results)+sum(yaml_judge_results))/(5*len(yaml_standard_results)),'.3f')}\")\n",
    "data_subsets = [\n",
    "    # Stratum of control on standard instruction\n",
    "    (np.array(yaml_standard_results), np.array(unstructured_standard_results)),\n",
    "    # Stratum of control on artist instruction\n",
    "    (np.array(yaml_artist_results), np.array(unstructured_artist_results)),\n",
    "    # Stratum of control on chef instruction\n",
    "    (np.array(yaml_chef_results), np.array(unstructured_chef_results)),\n",
    "    # Stratum of control on detective instruction\n",
    "    (np.array(yaml_detective_results), np.array(unstructured_detective_results)),\n",
    "    # Stratum of control on judge instruction\n",
    "    (np.array(yaml_judge_results), np.array(unstructured_judge_results)),\n",
    "]\n",
    "\n",
    "p_values = []\n",
    "\n",
    "for i, (correct_D, correct_E) in enumerate(data_subsets, 1):\n",
    "    # Build contingency table for this stratum\n",
    "    table = np.zeros((2, 2), dtype=int)\n",
    "    for d, e in zip(correct_D, correct_E):\n",
    "        table[d, e] += 1\n",
    "\n",
    "    # Run McNemar's test\n",
    "    result = mcnemar(table, exact=True)\n",
    "    p_values.append(result.pvalue)\n",
    "\n",
    "    # print(f\"Stratum {i} contingency table:\\n{table}\")\n",
    "    # print(f\"Stratum {i} McNemar p-value: {result.pvalue:.5f}\\n\")\n",
    "\n",
    "# Combine p-values using Stoufferâ€™s method with correlation adjustment\n",
    "# Convert p-values to Z-scores (two-sided)\n",
    "z_scores = norm.isf(np.array(p_values) / 2)  # inverse survival function\n",
    "\n",
    "# Assume weights (e.g., uniform or by number of samples per stratum)\n",
    "weights = np.ones_like(z_scores)\n",
    "# Assume correlation between strata (due to shared samples)\n",
    "rho = 0.3\n",
    "k = len(p_values)\n",
    "R = np.full((k, k), rho)\n",
    "np.fill_diagonal(R, 1)  # correlation matrix\n",
    "\n",
    "# Stouffer's Z with correlation adjustment\n",
    "numerator = np.sum(weights * z_scores)\n",
    "denominator = np.sqrt(np.dot(weights, R @ weights))\n",
    "z_combined = numerator / denominator\n",
    "p_combined = 2 * norm.sf(abs(z_combined))\n",
    "\n",
    "# print(f\"Combined Stouffer Z: {z_combined:.3f}\")\n",
    "print(f\"Combined p-value across strata (Stoufferâ€™s method): {p_combined:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9f1ffa-bcab-4986-9566-0878ba1986bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of unstructured & YAML format with standard instruction: 0.831\n",
      "Averaged accuracy of unstructured & YAML format with intervened instruction: 0.820\n",
      "Combined p-value across strata (Stoufferâ€™s method): 0.000\n"
     ]
    }
   ],
   "source": [
    "# Test whether instruction significantly influences LLMs' generation\n",
    "print(f\"Accuracy of unstructured & YAML format with standard instruction: {format((sum(unstructured_standard_results)+sum(yaml_standard_results))/(2*len(yaml_standard_results)),'.3f')}\")\n",
    "print(f\"Averaged accuracy of unstructured & YAML format with intervened instruction: {format((sum(unstructured_artist_results)+sum(unstructured_chef_results)+sum(unstructured_detective_results)+sum(unstructured_judge_results)+sum(yaml_artist_results)+sum(yaml_chef_results)+sum(yaml_detective_results)+sum(yaml_judge_results))/(8*len(yaml_standard_results)),'.3f')}\")\n",
    "\n",
    "stratum_yaml = np.array([yaml_standard_results, yaml_artist_results, yaml_chef_results, yaml_detective_results, yaml_judge_results]).transpose()\n",
    "stratum_unstructured = np.array([unstructured_standard_results, unstructured_artist_results, unstructured_chef_results, unstructured_detective_results, unstructured_judge_results]).transpose()\n",
    "data_strata = [stratum_yaml, stratum_unstructured]\n",
    "\n",
    "# Run Cochran's Q test on each stratum\n",
    "p_values = []\n",
    "# print(\"Cochran's Q test per stratum:\")\n",
    "for i, data in enumerate(data_strata):\n",
    "    result = cochrans_q(data)\n",
    "    p_values.append(result.pvalue)\n",
    "    # print(f\"  Stratum {i+1}: Q = {result.statistic:.4f}, p = {result.pvalue:.5f}\")\n",
    "    \n",
    "# Combine p-values using Stoufferâ€™s method with correlation adjustment\n",
    "# Convert p-values to Z-scores (two-sided)\n",
    "z_scores = norm.isf(np.array(p_values) / 2)  # inverse survival function\n",
    "\n",
    "# Assume weights (e.g., uniform or by number of samples per stratum)\n",
    "weights = np.ones_like(z_scores)\n",
    "# Assume correlation between strata (due to shared samples)\n",
    "rho = 0.3\n",
    "k = len(p_values)\n",
    "R = np.full((k, k), rho)\n",
    "np.fill_diagonal(R, 1)  # correlation matrix\n",
    "\n",
    "# Stouffer's Z with correlation adjustment\n",
    "numerator = np.sum(weights * z_scores)\n",
    "denominator = np.sqrt(np.dot(weights, R @ weights))\n",
    "z_combined = numerator / denominator\n",
    "p_combined = 2 * norm.sf(abs(z_combined))\n",
    "\n",
    "# print(f\"Combined Stouffer Z: {z_combined:.3f}\")\n",
    "print(f\"Combined p-value across strata (Stoufferâ€™s method): {p_combined:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e990be5-9296-4343-a583-53df87871375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If statistical significance threshold is 0.1\n",
    "# Test conditional association between output format and instruction type\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\n",
    "# Transform yaml_standard_results into dataframe\n",
    "# Comprising output format, instruction, and stratum of generation quality\n",
    "# Output format: 1 structured 0 unstructured\n",
    "# Instruction: 'a' standard 'b' artist 'c' chef 'd' detective 'e' judge\n",
    "# Generation qiality: 1 true 0 false\n",
    "df = pd.DataFrame({\n",
    "    'Z': np.concatenate([np.repeat('a', len(yaml_standard_results)),\n",
    "                         np.repeat('b', len(yaml_artist_results)),\n",
    "                         np.repeat('c', len(yaml_chef_results)),\n",
    "                         np.repeat('d', len(yaml_detective_results)),\n",
    "                         np.repeat('e', len(yaml_judge_results)),\n",
    "                         # Unstructured\n",
    "                         np.repeat('a', len(unstructured_standard_results)),\n",
    "                         np.repeat('b', len(unstructured_artist_results)),\n",
    "                         np.repeat('c', len(unstructured_chef_results)),\n",
    "                         np.repeat('d', len(unstructured_detective_results)),\n",
    "                         np.repeat('e', len(unstructured_judge_results)),\n",
    "                        ]),\n",
    "    'X': np.concatenate([np.repeat(1, len(yaml_standard_results)),\n",
    "                         np.repeat(1, len(yaml_artist_results)),\n",
    "                         np.repeat(1, len(yaml_chef_results)),\n",
    "                         np.repeat(1, len(yaml_detective_results)),\n",
    "                         np.repeat(1, len(yaml_judge_results)),\n",
    "                         # Unstructured\n",
    "                         np.repeat(0, len(unstructured_standard_results)),\n",
    "                         np.repeat(0, len(unstructured_artist_results)),\n",
    "                         np.repeat(0, len(unstructured_chef_results)),\n",
    "                         np.repeat(0, len(unstructured_detective_results)),\n",
    "                         np.repeat(0, len(unstructured_judge_results)),\n",
    "                        ]),\n",
    "    'Y': np.concatenate([np.repeat(0, len(np.where(np.array(yaml_standard_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(yaml_standard_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(yaml_artist_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(yaml_artist_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(yaml_chef_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(yaml_chef_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(yaml_detective_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(yaml_detective_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(yaml_judge_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(yaml_judge_results)==1)[0])),\n",
    "                         # Unstructured\n",
    "                         np.repeat(0, len(np.where(np.array(unstructured_standard_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(unstructured_standard_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(unstructured_artist_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(unstructured_artist_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(unstructured_chef_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(unstructured_chef_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(unstructured_detective_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(unstructured_detective_results)==1)[0])),\n",
    "                         np.repeat(0, len(np.where(np.array(unstructured_judge_results)==0)[0])),\n",
    "                         np.repeat(1, len(np.where(np.array(unstructured_judge_results)==1)[0])),\n",
    "                        ])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90019d08-8c25-472f-aa13-519dfd3ac0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Binomial Mixed GLM Results\n",
      "====================================================\n",
      "      Type Post. Mean Post. SD   SD  SD (LB) SD (UB)\n",
      "----------------------------------------------------\n",
      "const    M     0.0961   0.0452                      \n",
      "Z_b      M    -0.0012   0.1010                      \n",
      "Z_c      M    -0.0269   0.1011                      \n",
      "Z_d      M     0.0047   0.1010                      \n",
      "Z_e      M     0.0120   0.1010                      \n",
      "VC_1     V     0.0000   1.0000 1.000   0.135   7.389\n",
      "VC_2     V    -1.0755   0.5925 0.341   0.104   1.116\n",
      "====================================================\n",
      "Parameter types are mean structure (M) and variance\n",
      "structure (V)\n",
      "Variance parameters are modeled as log standard\n",
      "deviations\n"
     ]
    }
   ],
   "source": [
    "df_dummy = pd.get_dummies(df, columns=['Z'], drop_first=True)\n",
    "# Define model components\n",
    "endog = df_dummy['X']\n",
    "exog = sm.add_constant(df_dummy[[col for col in df_dummy.columns if col.startswith('Z_')]])  # fixed effects\n",
    "groups = df_dummy['Y']\n",
    "exog_re = pd.get_dummies(groups)  # random intercepts per stratum\n",
    "ident = np.ones(exog_re.shape[1], dtype=int)\n",
    "# Fit mixed logistic model\n",
    "model = BinomialBayesMixedGLM(endog, exog, exog_re, ident=ident)\n",
    "result = model.fit_vb()\n",
    "# Print results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eec2293-3cb1-414c-adb8-ea535b7499f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const                coef =  0.0961, SE = 0.0452, z = 2.12, p = 0.0336\n",
      "Z_b                  coef = -0.0012, SE = 0.1010, z = -0.01, p = 0.9906\n",
      "Z_c                  coef = -0.0269, SE = 0.1011, z = -0.27, p = 0.7903\n",
      "Z_d                  coef =  0.0047, SE = 0.1010, z = 0.05, p = 0.9631\n",
      "Z_e                  coef =  0.0120, SE = 0.1010, z = 0.12, p = 0.9054\n"
     ]
    }
   ],
   "source": [
    "# Extract coefficient names, values, and std errors\n",
    "param_names = model.exog_names  # names of fixed effects (same order as fe_mean)\n",
    "coefs = result.fe_mean          # posterior means of fixed effects\n",
    "ses = result.fe_sd              # posterior standard deviations\n",
    "\n",
    "# Compute z-scores and p-values\n",
    "z_scores = coefs / ses\n",
    "p_values = 2 * (1 - norm.cdf(np.abs(z_scores)))  # two-tailed p-values\n",
    "\n",
    "# Display results\n",
    "for name, coef, se, z, p in zip(param_names, coefs, ses, z_scores, p_values):\n",
    "    print(f\"{name:20} coef = {coef: .4f}, SE = {se:.4f}, z = {z:.2f}, p = {p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca94dd51-e610-4697-8244-1b855ed209fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy of unstructured format with diverse instruction (all samples): 0.836\n"
     ]
    }
   ],
   "source": [
    "def read_unstructured_parsed_all(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    answers = []\n",
    "    if isinstance(data, list):\n",
    "        for obj in data:\n",
    "            if isinstance(obj, dict) and \"parsed\" in obj:\n",
    "                number = str(obj[\"parsed\"]).replace(',', '')\n",
    "                number = re.findall(r'\\d+\\.\\d+|\\d+', number)\n",
    "            if len(number) != 0:\n",
    "                answers.append(number[0])\n",
    "            else:\n",
    "                answers.append('10086')\n",
    "    return answers\n",
    "\n",
    "# Unstructured answers (all samples)\n",
    "unstructured_standard_answers = read_unstructured_parsed_all(\"results/llama_8b_unstructured_parsed.json\")\n",
    "unstructured_artist_answers = read_unstructured_parsed_all(\"results/llama_8b_unstructured_artist_parsed.json\")\n",
    "unstructured_chef_answers = read_unstructured_parsed_all(\"results/llama_8b_unstructured_chef_parsed.json\")\n",
    "unstructured_detective_answers = read_unstructured_parsed_all(\"results/llama_8b_unstructured_detective_parsed.json\")\n",
    "unstructured_judge_answers = read_unstructured_parsed_all(\"results/llama_8b_unstructured_judge_parsed.json\")\n",
    "\n",
    "unstructured_standard_results = []\n",
    "unstructured_artist_results = []\n",
    "unstructured_chef_results = []\n",
    "unstructured_detective_results = []\n",
    "unstructured_judge_results = []\n",
    "\n",
    "with open(\"../data/gsm8k_test.json\", \"r\") as f:\n",
    "    label = json.load(f)\n",
    "\n",
    "for i in range(len(unstructured_standard_answers)):\n",
    "    label_tmp = float(label[i]['answer'].split(\"\\n#### \")[-1].replace(',', ''))\n",
    "    # Unstructured answers\n",
    "    if label_tmp == float(unstructured_standard_answers[i]):\n",
    "        unstructured_standard_results.append(1)\n",
    "    else:\n",
    "        unstructured_standard_results.append(0)\n",
    "        \n",
    "    if label_tmp == float(unstructured_artist_answers[i]):\n",
    "        unstructured_artist_results.append(1)\n",
    "    else:\n",
    "        unstructured_artist_results.append(0)\n",
    "        \n",
    "    if label_tmp == float(unstructured_chef_answers[i]):\n",
    "        unstructured_chef_results.append(1)\n",
    "    else:\n",
    "        unstructured_chef_results.append(0)\n",
    "        \n",
    "    if label_tmp == float(unstructured_detective_answers[i]):\n",
    "        unstructured_detective_results.append(1)\n",
    "    else:\n",
    "        unstructured_detective_results.append(0)\n",
    "        \n",
    "    if label_tmp == float(unstructured_judge_answers[i]):\n",
    "        unstructured_judge_results.append(1)\n",
    "    else:\n",
    "        unstructured_judge_results.append(0)\n",
    "\n",
    "print(f\"Averaged accuracy of unstructured format with diverse instruction (all samples): {format((sum(unstructured_standard_results)+sum(unstructured_artist_results)+sum(unstructured_chef_results)+sum(unstructured_detective_results)+sum(unstructured_judge_results))/(5*len(unstructured_standard_results)),'.3f')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
